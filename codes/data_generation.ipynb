{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_generation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Sm60bDDBmh9c_d1Y1cGrI98quwZX4ZeO","authorship_tag":"ABX9TyPHay6jwuklTJ+9gSRzPNn0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"maV7eTCCjMMq"},"source":["installing essential packages:"]},{"cell_type":"code","metadata":{"id":"bRkW6mvdi4h_"},"source":["!pip install git+https://github.com/vafaei-ar/ccgpack.git\n","!pip install healpy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u9fTaryzjjMA"},"source":["importing essential packages:"]},{"cell_type":"code","metadata":{"id":"FyGVqFw7joqH"},"source":["import numpy as np\n","import healpy as hp\n","import ccgpack as ccg\n","import torch\n","from torch.utils.data import TensorDataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EeYfv1aQl017"},"source":["In this step, I import one of the images (in this example, alms15) and save it in 2 parameters named \"filename_l\" and \"filename_nl\" (note that I've already downloaded images and stored them in alms folder). In the following, the alm_l (Gaussian part) and alm_nl (non-Gaussian part) can be derived from them: "]},{"cell_type":"code","metadata":{"id":"tdm2m-b4jp8J"},"source":["filename_l = '/content/drive/MyDrive/alms/alms15/alm_l_0015_v3.fits/alm_l_0015_v3.fits' # you have to enter the address of alm_l file\n","filename_nl = '/content/drive/MyDrive/alms/alms15/alm_nl_0015_v3.fits/alm_nl_0015_v3.fits' # you have to enter the address of alm_nl file\n","alm_l  = hp.fitsfunc.read_alm(filename_l, hdu=1) # reading alm_l file using healpy\n","alm_nl = hp.fitsfunc.read_alm(filename_nl, hdu=1) # reading alm_nl file using healpy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rixp5CahxGXH"},"source":["f_NL is desired level of non-Gaussianity which can be any arbitrary number (in this example is 100)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Esjro_bxFWH","executionInfo":{"status":"ok","timestamp":1631737010879,"user_tz":-270,"elapsed":17664,"user":{"displayName":"hosein salahshoor","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18076820241113126701"}},"outputId":"95c11319-c07e-4217-b831-9346ae3b1642"},"source":["f_NL = 100\n","alm = alm_l + f_NL * alm_nl # the principal formula for adding non_Gaussianity\n","map = hp.sphtfunc.alm2map(alm, nside=2048, lmax=1024, fwhm=0.0, verbose=True) # Computes a Healpix map given the alm (nside is the resolution of the map)\n","map = hp.reorder(map,r2n=1)\n","map -= np.min(map) # shifting minimum to zero\n","map /= (np.max(map)/255.)\n","patch = ccg.sky2patch(map,8) # each map divides into 64 part\n","print (patch.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING: AstropyDeprecationWarning: \"verbose\" was deprecated in version 1.15.0 and will be removed in a future version.  [warnings]\n"]},{"output_type":"stream","name":"stdout","text":["(768, 256, 256)\n"]}]},{"cell_type":"markdown","metadata":{"id":"e-JPuk_KHk7E"},"source":["As you can see, we created 768 different patches with f_NL = 100 from alms15. \n","To create a complete data, you have to save all of these patches (with a definite f_NL) into a single file using ```np.concatenate``` function. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QiotEaHineQX"},"source":["After that, I create labels using ```np.full```. For example:"]},{"cell_type":"code","metadata":{"id":"3WxPoHtfnyXC"},"source":["lbl = np.full((768,1),0) \n","# if the number of your data is bigger than 768, you have to change this number here!\n","# I choose the label of 100 to be one (in pytorch, the range of your labels depends on the number of network's output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mi-tAtQjvFsg"},"source":["At the end, I make a tensor-base data set using ```TensorDataset```"]},{"cell_type":"code","metadata":{"id":"CxESCivXvWt9"},"source":["dataset = TensorDataset(torch.tensor(image).unsqueeze(1), torch.tensor(lbl).squeeze())\n","# Note: CNN layesr only accept 4D arrays, so we have to unsqueeze images\n","# Note: the CrossEntropyLoss only accepts 1D labels, so I have to squeeze additional dimension"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YF6V3k89wwbg"},"source":["As explained above, our dataset has generated. But we could adopt another approach to create them. For examplem, we can save images one by one:"]},{"cell_type":"code","metadata":{"id":"hpVeVk8hiIgG"},"source":["for i in range(768):\n","  im = patch[i]\n","  np.save('/content/.../1{}'.format(i),im) # again, my label is 1 which corresponds to 100 (you can use this trick to load labels too)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"618EO9xExsRg"},"source":["This is helpful when you want extract label from the image's name. Although, in this way, you must define a customized data loader"]}]}
